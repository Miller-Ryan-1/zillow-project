{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9682180",
   "metadata": {},
   "source": [
    "# I. Initial Imports (more found throughout workbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba32ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "import explore\n",
    "\n",
    "from acquire import get_zillow_data\n",
    "from wrangle import wrangle_zillow\n",
    "from wrangle import scale_zillow\n",
    "from splitter import splitter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0097423",
   "metadata": {},
   "source": [
    "# II. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6732e17",
   "metadata": {},
   "source": [
    "## Step 1 - Dataset analyzed in SQL\n",
    "- Decided on features to use from properties_2017 table based on initial analysis (and hypothesis) that the following numerical features are important: Year built, number of bathrooms and bedrooms, building quality type (on a scale from 1-12, but continuous), calculated finsihed square feet, lot size in square feet, and the number of fireplaces, pools and garages.  Selected one categorical feature, fips.  \n",
    "- Right joined with predictions_2017 on 'parcelid'\n",
    "- See acquire.py for SQL query used (to include features selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09051620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft</th>\n",
       "      <th>valuation</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>quality</th>\n",
       "      <th>fireplaces</th>\n",
       "      <th>lotsize</th>\n",
       "      <th>pools</th>\n",
       "      <th>garages</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46501</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4510.0</td>\n",
       "      <td>2546378.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7886.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1835.0</td>\n",
       "      <td>62048.0</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19618</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2263.0</td>\n",
       "      <td>337404.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7280.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21546</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>601100.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2499.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15950</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>389610.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6626.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bedrooms  bathrooms    sqft  valuation  yearbuilt  quality  fireplaces  \\\n",
       "46501       5.0        4.0  4510.0  2546378.0     2012.0     11.0         NaN   \n",
       "1749        4.0        2.0  1835.0    62048.0     1964.0      NaN         1.0   \n",
       "19618       3.0        2.0  2263.0   337404.0     1972.0      NaN         NaN   \n",
       "21546       4.0        4.0  1890.0   601100.0     2004.0      7.0         NaN   \n",
       "15950       3.0        1.0  1066.0   389610.0     1950.0      4.0         NaN   \n",
       "\n",
       "       lotsize  pools  garages    fips  \n",
       "46501   7886.0    NaN      NaN  6037.0  \n",
       "1749    6500.0    NaN      2.0  6111.0  \n",
       "19618   7280.0    NaN      2.0  6059.0  \n",
       "21546   2499.0    NaN      NaN  6037.0  \n",
       "15950   6626.0    NaN      NaN  6037.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_zillow_data()\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b1fc8",
   "metadata": {},
   "source": [
    "## Step 2 - Examine data to determine how to prep/clean (for wrangle.py file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0090e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db06a6",
   "metadata": {},
   "source": [
    "##### Check for dupliactes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7db1b361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 52442 entries, 0 to 52441\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   bedrooms    52442 non-null  float64\n",
      " 1   bathrooms   52442 non-null  float64\n",
      " 2   sqft        52360 non-null  float64\n",
      " 3   valuation   52441 non-null  float64\n",
      " 4   yearbuilt   52326 non-null  float64\n",
      " 5   quality     33741 non-null  float64\n",
      " 6   fireplaces  7243 non-null   float64\n",
      " 7   lotsize     52073 non-null  float64\n",
      " 8   pools       11096 non-null  float64\n",
      " 9   garages     18015 non-null  float64\n",
      " 10  fips        52442 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 4.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c0bf4d",
   "metadata": {},
   "source": [
    "##### Run value counts on all columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c34352c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedrooms\n",
      "3.0    23186\n",
      "4.0    14994\n",
      "2.0     8211\n",
      "5.0     3774\n",
      "1.0      543\n",
      "6.0      540\n",
      "Name: bedrooms, dtype: int64\n",
      "0 null values\n",
      "\n",
      "-----\n",
      "\n",
      "bathrooms\n",
      "2.0    21758\n",
      "3.0    10485\n",
      "1.0     9438\n",
      "2.5     3917\n",
      "4.0     2106\n",
      "3.5      892\n",
      "1.5      822\n",
      "5.0      713\n",
      "4.5      645\n",
      "6.0      245\n",
      "5.5      198\n",
      "6.5       29\n",
      "Name: bathrooms, dtype: int64\n",
      "0 null values\n",
      "\n",
      "-----\n",
      "\n",
      "sqft\n",
      "1120.0    127\n",
      "1200.0    118\n",
      "1080.0     93\n",
      "936.0      86\n",
      "1176.0     83\n",
      "         ... \n",
      "3707.0      1\n",
      "4591.0      1\n",
      "4215.0      1\n",
      "3559.0      1\n",
      "5350.0      1\n",
      "Name: sqft, Length: 4388, dtype: int64\n",
      "0 null values\n",
      "\n",
      "-----\n",
      "\n",
      "valuation\n",
      "455000.0    34\n",
      "600000.0    30\n",
      "500000.0    24\n",
      "450000.0    24\n",
      "550000.0    24\n",
      "            ..\n",
      "977685.0     1\n",
      "348301.0     1\n",
      "502027.0     1\n",
      "455180.0     1\n",
      "49546.0      1\n",
      "Name: valuation, Length: 37998, dtype: int64\n",
      "0 null values\n",
      "\n",
      "-----\n",
      "\n",
      "yearbuilt\n",
      "1955.0    1889\n",
      "1950.0    1594\n",
      "1954.0    1511\n",
      "1953.0    1480\n",
      "1956.0    1373\n",
      "          ... \n",
      "1892.0       1\n",
      "1878.0       1\n",
      "1882.0       1\n",
      "1894.0       1\n",
      "1880.0       1\n",
      "Name: yearbuilt, Length: 133, dtype: int64\n",
      "0 null values\n",
      "\n",
      "-----\n",
      "\n",
      "fireplaces\n",
      "0.0    44141\n",
      "1.0     5977\n",
      "2.0      915\n",
      "3.0      215\n",
      "Name: fireplaces, dtype: int64\n",
      "0 null values\n",
      "\n",
      "-----\n",
      "\n",
      "lotsize\n",
      "6000.0     876\n",
      "5000.0     412\n",
      "7200.0     306\n",
      "7000.0     286\n",
      "6500.0     271\n",
      "          ... \n",
      "9028.0       1\n",
      "18868.0      1\n",
      "9894.0       1\n",
      "3808.0       1\n",
      "47405.0      1\n",
      "Name: lotsize, Length: 13823, dtype: int64\n",
      "0 null values\n",
      "\n",
      "-----\n",
      "\n",
      "pools\n",
      "0.0    40578\n",
      "1.0    10670\n",
      "Name: pools, dtype: int64\n",
      "0 null values\n",
      "\n",
      "-----\n",
      "\n",
      "garages\n",
      "0.0    33586\n",
      "2.0    14700\n",
      "1.0     2157\n",
      "3.0      589\n",
      "4.0      216\n",
      "Name: garages, dtype: int64\n",
      "0 null values\n",
      "\n",
      "-----\n",
      "\n",
      "fips_name\n",
      "Los Angeles    33106\n",
      "Orange         13876\n",
      "Ventura         4266\n",
      "Name: fips_name, dtype: int64\n",
      "0 null values\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i)\n",
    "    print(df[i].value_counts())\n",
    "    print(f'{df[df[i].isnull()].shape[0]} null values')\n",
    "    print('\\n-----\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332969df",
   "metadata": {},
   "source": [
    "##### After examination of the value counts, my initial cleaning consists of the following:\n",
    "1. It seems that fireplaces, pools and garages are all NaN if they have none.  Therefore, I will replace all their NaNs with a zero.\n",
    "2. I need to investigate the quality score more, as it has a very large number of Nulls.  Quality is a metric from 1 (best) to 12 (worst).  Is there a way to fill in those numbers based on other features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc24acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft</th>\n",
       "      <th>valuation</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>quality</th>\n",
       "      <th>fireplaces</th>\n",
       "      <th>lotsize</th>\n",
       "      <th>pools</th>\n",
       "      <th>garages</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1023282.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4506.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>464000.0</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12647.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6111.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms    sqft  valuation  yearbuilt  quality  fireplaces  \\\n",
       "0       4.0        3.5  3100.0  1023282.0     1998.0      NaN         0.0   \n",
       "1       2.0        1.0  1465.0   464000.0     1967.0      NaN         1.0   \n",
       "\n",
       "   lotsize  pools  garages    fips  \n",
       "0   4506.0    0.0      2.0  6059.0  \n",
       "1  12647.0    0.0      1.0  6111.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fireplaces'] = df.fireplaces.fillna(value=0)\n",
    "df['pools'] = df.pools.fillna(value=0)\n",
    "df['garages'] = df.garages.fillna(value=0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c40e422",
   "metadata": {},
   "source": [
    "##### Quality Investigation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbb872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with no nulls for quality analysis\n",
    "df_qual = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d4e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qual.quality.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1fc603",
   "metadata": {},
   "source": [
    "Since the quality graph is somewhat normal, I think I can use a linear model to fill those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba08e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_qual, x='fips_name', y='quality')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0c09b6",
   "metadata": {},
   "source": [
    "Aha, is only good for Los Angeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d287f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_qual.drop(columns=['quality'])\n",
    "y = df_qual.quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e610218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "ols_model = LinearRegression().fit(X,y)\n",
    "\n",
    "df_qual['yhat'] = ols_model.predict(X)\n",
    "\n",
    "df_qual.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1672cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "yhat = df_qual.yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8f0639",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.better_than_baseline(y,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92fcc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58da09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = df.quality\n",
    "quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec336e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = 'quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b33fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df['quality'] = quality\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43519d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['quality'])\n",
    "df['yhat'] = ols_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ae227",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'] = df.quality.fillna(value=df.yhat)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5174faef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.quality.max(), df.quality.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b03519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(y_validate.G3, color='blue', alpha=.5, label=\"Actual Final Grades\")\n",
    "plt.figure(figsize = (12,6))\n",
    "plt.hist(df.quality, color='blue', alpha = .5, label = 'Quality', bins=24)\n",
    "plt.hist(df.yhat, color='orange',alpha = .25, label = 'yhat', bins=24)\n",
    "plt.legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab02731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['quality']<2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15914e80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['quality']>12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebb1b47",
   "metadata": {},
   "source": [
    "##### After examining the quality scores, I feel they may be too subjective to be correlated to other features, even with the linear regression model having a higher baseline RMSE (although it was fairly minor).  Looking at the extreme values, there seems to be nothing tha sticks out about either end (<2, >12) other than most of the >12 are actually huge houses with high doller values.\n",
    "\n",
    "##### Therefore, I will drop quality from my main df examination, but plan on running a seperate analysis on only those who have a quality score as well as the other features being examined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23f6a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae89509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col)\n",
    "    df[col].hist()\n",
    "    plt.show()\n",
    "    print(100*df[col].value_counts()/df.shape[0])\n",
    "    print('\\n-----\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11004319",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['lotsize']>217800]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a29754",
   "metadata": {},
   "source": [
    "##### I used the following general line of code to examine each feature in details to determine where to cut values off: df[df[feature]>n].sort_values(by=feature)\n",
    "\n",
    "##### From this I determined the following to remove some of the larger outliers, to be done in wrangle:\n",
    "1. Set range of bedrooms and bathrooms from 1-6 (0<b<7)\n",
    "2. Remove all listings with a home size greater than 10,000 sqft and less than 400 sqft\n",
    "3. Remove all listings with more than 4 garages (g<5)\n",
    "4. Remove all listing with more than 3 fireplaces (f<4)\n",
    "5. Remove listings with a valuation greater than \\$10MM or less than 10k\n",
    "6. Remove all listings with a lot size greater than 217,800 sqft (5 acres)\n",
    "7. Also remove all listings with a lot size less than 1/2 the sqft of the home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed3ffbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='quality')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae517981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9862971516551193"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['bathrooms'] > 0]\n",
    "df = df[df['bedrooms'] > 0]\n",
    "df = df[df['bathrooms'] < 7]\n",
    "df = df[df['bedrooms'] < 7]\n",
    "df = df[df['sqft'] > 400]\n",
    "df = df[df['sqft'] < 10000]\n",
    "df = df[df['valuation'] > 10000]\n",
    "df = df[df['valuation'] < 5000000]\n",
    "df = df[df['fireplaces'] < 4]\n",
    "df = df[df['garages'] < 5]\n",
    "df = df[df['lotsize'] < 217800]\n",
    "df = df[df['lotsize'] > (.5 * df['sqft'])]\n",
    "df.shape[0]/51960"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5baa4f0",
   "metadata": {},
   "source": [
    "This leaves ~98.6% of the records for exploration and modeling.\n",
    "\n",
    "In addition to removing these listings, I will also convert floats to integers, where applicable, and rename the fips with their actual names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddc94e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fips_name'] = np.where(df.fips == 6037, 'Los Angeles', np.where(df.fips == 6059, 'Orange','Ventura') )\n",
    "df = df.drop(columns = 'fips')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848288b",
   "metadata": {},
   "source": [
    "# III. Univariate Plots and Initial Hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c99b6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col)\n",
    "    sns.boxplot(y=df[col].values)\n",
    "    plt.show()\n",
    "    print('\\n-----\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79edc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x='fips_name',data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cddc94",
   "metadata": {},
   "source": [
    "## Initial Hypotheses\n",
    "1. Having a fireplace(s), garage(s) and/or pool increases home value.\n",
    "2. Larger lot size increases home value.\n",
    "3. Larger square foot size increases home value.\n",
    "4. More bedrooms and bathrooms increase home value.\n",
    "5. There is a difference in home values due to geography."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d95f76",
   "metadata": {},
   "source": [
    "# IV. Bivariate and Multivariate EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d28afaf",
   "metadata": {},
   "source": [
    "#### First, we must split the data.  I want to ensure the categorical variable, fips name, is equally distributed across the splits, so I will stratify on fips_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "861153e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train = 28698 rows (56.0%) | Validate = 12300 rows (24.0%) | Test = 10250 rows (20.0%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft</th>\n",
       "      <th>valuation</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>fireplaces</th>\n",
       "      <th>lotsize</th>\n",
       "      <th>pools</th>\n",
       "      <th>garages</th>\n",
       "      <th>fips_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24401</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1163.0</td>\n",
       "      <td>505000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3757.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ventura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11376</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2633.0</td>\n",
       "      <td>420576.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bedrooms  bathrooms    sqft  valuation  yearbuilt  fireplaces  lotsize  \\\n",
       "24401       3.0        2.0  1163.0   505000.0     2000.0         1.0   3757.0   \n",
       "11376       4.0        3.0  2633.0   420576.0     1994.0         0.0   8000.0   \n",
       "\n",
       "       pools  garages fips_name  \n",
       "24401    0.0      1.0   Ventura  \n",
       "11376    0.0      2.0    Orange  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validate, test = splitter(df, target='fips_name')\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3435f5d0",
   "metadata": {},
   "source": [
    "Plot all variable pairs to look for correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02621dec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explore.plot_variable_pairs(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7318f223",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explore.plot_categorical_and_continuous_vars(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce39db5",
   "metadata": {},
   "source": [
    "Plot all variables against target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c708e8ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_cols = [col for col in train.columns if train[col].dtype != 'object']\n",
    "\n",
    "for i in num_cols:\n",
    "    sns.lmplot(data = train, x=i, y='valuation', col = 'fips_name')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10634bf8",
   "metadata": {},
   "source": [
    "##### Looking at the charts, I see that there are no garages or fireplaces for any of the Los Angeles homes.  Since LA is the majority of the dataset, I will remove these features as unimportant.  Thinking about statistical tests:\n",
    "1. Homes with pools have a higher valuation than homes without. (t-test)\n",
    "2. Orange county has the highest valuation, followed by Ventura and then LA (mutliple t-tests)\n",
    "3. More bathrooms correlated with higher valuation (pearsons)\n",
    "4. More bedrooms correlated with higher valuation (pearsons)\n",
    "5. Higher square footage correlated with higher valuation (pearsons)\n",
    "6. Larger lot size correlated with higher valuations (pearsons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf4235",
   "metadata": {},
   "source": [
    "## Hypotheses testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c20346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "alpha = .05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64e436c",
   "metadata": {},
   "source": [
    "#### 1. Do homes with pools have a higher valuation than homes without? (one-sided, independent t-test)\n",
    "\n",
    "$H_{0}$ = Homes with pools have the same or lower valuations than homes without.\n",
    "\n",
    "$H_{1}$ = Homes with pools have a higher valuation than homes without.\n",
    "\n",
    "Assumptions: (X)Independent | (X) Normal (or 30+ obs) | (?) Equal variances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39985476",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[train['pools']==1].valuation.var())\n",
    "print(train[train['pools']==0].valuation.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca37b3b1",
   "metadata": {},
   "source": [
    "*Must set equal_var to False*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_ind(train[train['pools']==1].valuation, train[train['pools']==0].valuation, equal_var=False)\n",
    "t, p / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b95f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is t < 0? \", t < 0)\n",
    "print(\"is p/2 < alpha? \", p / 2 < alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeff7086",
   "metadata": {},
   "source": [
    "We REJECT the null hypothesis that homes with pools have the same or lower valuations than homes without. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc8958",
   "metadata": {},
   "source": [
    "#### 2. Does Orange county have the highest mean valuations followed by Ventura and then LA? (mutliple one sided, independent t-tests)\n",
    "$H_{0}$ = X-fip has the same or lower valuations than Y-fip without.\n",
    "\n",
    "$H_{1}$ = X-fip has a higher valuation than Y-fip without.\n",
    "\n",
    "where X1 is Orange, Y1 is Ventura, X2 is Ventura and Y2 is Los Angeles\n",
    "\n",
    "Assumptions: (X)Independent | (X) Normal (or 30+ obs) | (?) Equal variances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8f4203",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[train['fips_name']=='Orange'].valuation.var())\n",
    "print(train[train['fips_name']=='Ventura'].valuation.var())\n",
    "print(train[train['fips_name']=='Los Angeles'].valuation.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8cff27",
   "metadata": {},
   "source": [
    "*While Orange and LA have equal variances, I'll go ahead and set to False when comparing to Ventura*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4536b8f",
   "metadata": {},
   "source": [
    "1. Orange vs Ventura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac1cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_ind(train[train['fips_name']=='Orange'].valuation, train[train['fips_name']=='Ventura'].valuation, equal_var=False)\n",
    "t, p / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eb4156",
   "metadata": {},
   "source": [
    "We REJECT the null hypothesis that Orange has the same or lower valuations than Ventura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd405892",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_ind(train[train['fips_name']=='Ventura'].valuation, train[train['fips_name']=='Los Angeles'].valuation, equal_var=False)\n",
    "t, p / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5affa6",
   "metadata": {},
   "source": [
    "We REJECT the null hypothesis that Ventura has the same or lower valuations than Los Angeles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f8217",
   "metadata": {},
   "source": [
    "#### 3. More bathrooms correlated with valuation (pearsons)\n",
    "$H_{0}$ = Bathrooms are not correlated with valuation.\n",
    "\n",
    "$H_{1}$ = Bathrooms are correlated with valuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a17e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, p = stats.pearsonr(train.bathrooms, train.valuation)\n",
    "corr, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d62cde",
   "metadata": {},
   "source": [
    "We REJECT the null hypothesis that bathrooms are not correlated with valuation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3db7dca",
   "metadata": {},
   "source": [
    "#### 4. More bedrooms correlated with higher valuation (pearsons)\n",
    "$H_{0}$ = Bedrooms are not correlated with valuation.\n",
    "\n",
    "$H_{1}$ = Bedrooms are correlated with valuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b19370",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, p = stats.pearsonr(train.bedrooms, train.valuation)\n",
    "corr, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99728e96",
   "metadata": {},
   "source": [
    "We REJECT the null hypothesis that bathrooms are not correlated with valuation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff169f1",
   "metadata": {},
   "source": [
    "#### 5. Higher square footage correlated with higher valuation (pearsons)\n",
    "$H_{0}$ = Square footage of home is not correlated with valuation.\n",
    "\n",
    "$H_{1}$ = Square footage of home is correlated with valuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab353859",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, p = stats.pearsonr(train.sqft, train.valuation)\n",
    "corr, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6aed62",
   "metadata": {},
   "source": [
    "We REJECT the null hypothesis that square footage of him is not correlated with valuation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3ce96e",
   "metadata": {},
   "source": [
    "#### 6. Larger lot size correlated with higher valuations (pearsons)\n",
    "$H_{0}$ = Lot size is not correlated with valuation.\n",
    "\n",
    "$H_{1}$ = Lot size is correlated with valuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ac455",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, p = stats.pearsonr(train.lotsize, train.valuation)\n",
    "corr, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fef3e30",
   "metadata": {},
   "source": [
    "We REJECT the null hypothesis that lot size is not correlated with valuation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0176a743",
   "metadata": {},
   "source": [
    "### *Sidequest: Quality Investigation EDA*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed05f7",
   "metadata": {},
   "source": [
    "##### Quick EDA examining Quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adccaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qual = df_qual.drop(columns = ['fireplaces','bathrooms','garages'])\n",
    "df_qual.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qual = df_qual.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0344409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qual['fips_name'] = np.where(df_qual.fips == 6037, 'Los Angeles', np.where(df_qual.fips == 6059, 'Orange','Ventura') )\n",
    "df_qual = df_qual.drop(columns = 'fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448eca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qual = df_qual[df_qual['bedrooms'] > 0]\n",
    "df_qual = df_qual[df_qual['bedrooms'] < 7]\n",
    "df_qual = df_qual[df_qual['sqft'] > 400]\n",
    "df_qual = df_qual[df_qual['sqft'] < 10000]\n",
    "df_qual = df_qual[df_qual['valuation'] > 10000]\n",
    "df_qual = df_qual[df_qual['valuation'] < 5000000]\n",
    "df_qual = df_qual[df_qual['lotsize'] < 217800]\n",
    "df_qual = df_qual[df_qual['lotsize'] > (.5 * df_qual['sqft'])]\n",
    "df_qual.shape[0]/33434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688234f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual, validate_qual, test_qual = splitter(df_qual, target='fips_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f8b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = train_qual, x='quality', y='valuation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0cc456",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, p = stats.pearsonr(train_qual.quality, train_qual.valuation)\n",
    "corr, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceefa1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual.fips_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c75fa14",
   "metadata": {},
   "source": [
    "## EDA Outcomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32922ac7",
   "metadata": {},
   "source": [
    "1. Orange county is associated with the highest valuation, then Ventura then LA.\n",
    "2. Bathrooms correlated with square feet, adn sqft better corelated with valiuation so dropping bathrooms.\n",
    "3. Quality seems well correlated with valuations, and the metrics seems wrong (higher seems better), so worth more investigation.\n",
    "4. Bedrooms are relevant so keep them\n",
    "5. Pools are so keep them\n",
    "6. Lot size and pool correlated with higher valuations, albeit not as strongly.\n",
    "7. Dropping garages and fireplaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6251642",
   "metadata": {},
   "source": [
    "# V. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c8cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1717dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.astype({'bedrooms':'int', 'sqft':'int', 'valuation':'int', 'yearbuilt':'int','fireplaces':'int','lotsize':'int','pools':'int','garages':'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71ce13a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>sqft</th>\n",
       "      <th>valuation</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>lotsize</th>\n",
       "      <th>pools</th>\n",
       "      <th>fips_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24401</th>\n",
       "      <td>3</td>\n",
       "      <td>1163</td>\n",
       "      <td>505000</td>\n",
       "      <td>2000</td>\n",
       "      <td>3757</td>\n",
       "      <td>0</td>\n",
       "      <td>Ventura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11376</th>\n",
       "      <td>4</td>\n",
       "      <td>2633</td>\n",
       "      <td>420576</td>\n",
       "      <td>1994</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41985</th>\n",
       "      <td>3</td>\n",
       "      <td>1401</td>\n",
       "      <td>320607</td>\n",
       "      <td>1937</td>\n",
       "      <td>5963</td>\n",
       "      <td>1</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>5</td>\n",
       "      <td>3762</td>\n",
       "      <td>1057082</td>\n",
       "      <td>1980</td>\n",
       "      <td>20366</td>\n",
       "      <td>1</td>\n",
       "      <td>Ventura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8066</th>\n",
       "      <td>5</td>\n",
       "      <td>3170</td>\n",
       "      <td>777109</td>\n",
       "      <td>1979</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38232</th>\n",
       "      <td>3</td>\n",
       "      <td>939</td>\n",
       "      <td>350260</td>\n",
       "      <td>1962</td>\n",
       "      <td>4997</td>\n",
       "      <td>0</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>3</td>\n",
       "      <td>1825</td>\n",
       "      <td>334507</td>\n",
       "      <td>1964</td>\n",
       "      <td>7800</td>\n",
       "      <td>0</td>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45700</th>\n",
       "      <td>3</td>\n",
       "      <td>2084</td>\n",
       "      <td>268418</td>\n",
       "      <td>1969</td>\n",
       "      <td>7200</td>\n",
       "      <td>1</td>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38230</th>\n",
       "      <td>5</td>\n",
       "      <td>5540</td>\n",
       "      <td>2979716</td>\n",
       "      <td>1928</td>\n",
       "      <td>37133</td>\n",
       "      <td>1</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18737</th>\n",
       "      <td>3</td>\n",
       "      <td>1162</td>\n",
       "      <td>377806</td>\n",
       "      <td>1947</td>\n",
       "      <td>6653</td>\n",
       "      <td>0</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28698 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bedrooms  sqft  valuation  yearbuilt  lotsize  pools    fips_name\n",
       "24401         3  1163     505000       2000     3757      0      Ventura\n",
       "11376         4  2633     420576       1994     8000      0       Orange\n",
       "41985         3  1401     320607       1937     5963      1  Los Angeles\n",
       "1184          5  3762    1057082       1980    20366      1      Ventura\n",
       "8066          5  3170     777109       1979    10000      1       Orange\n",
       "...         ...   ...        ...        ...      ...    ...          ...\n",
       "38232         3   939     350260       1962     4997      0  Los Angeles\n",
       "6148          3  1825     334507       1964     7800      0       Orange\n",
       "45700         3  2084     268418       1969     7200      1       Orange\n",
       "38230         5  5540    2979716       1928    37133      1  Los Angeles\n",
       "18737         3  1162     377806       1947     6653      0  Los Angeles\n",
       "\n",
       "[28698 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_remove = ['bathrooms','fireplaces','garages']\n",
    "train = train.drop(columns = columns_to_remove)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a4ac86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = validate.astype({'bedrooms':'int', 'sqft':'int', 'valuation':'int', 'yearbuilt':'int','fireplaces':'int','lotsize':'int','pools':'int','garages':'int'})\n",
    "test = test.astype({'bedrooms':'int', 'sqft':'int', 'valuation':'int', 'yearbuilt':'int','fireplaces':'int','lotsize':'int','pools':'int','garages':'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ab831c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = validate.drop(columns = columns_to_remove)\n",
    "test = test.drop(columns = columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7959d88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>sqft</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>lotsize</th>\n",
       "      <th>pools</th>\n",
       "      <th>fips_name</th>\n",
       "      <th>valuation</th>\n",
       "      <th>fips_name_Los Angeles</th>\n",
       "      <th>fips_name_Orange</th>\n",
       "      <th>fips_name_Ventura</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11614</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.072978</td>\n",
       "      <td>0.566176</td>\n",
       "      <td>0.030479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Orange</td>\n",
       "      <td>431697</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24479</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.090544</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.033159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>84959</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35314</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.174040</td>\n",
       "      <td>0.242647</td>\n",
       "      <td>0.031074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>693683</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.144546</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.039603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>494867</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35388</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.227825</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.017195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Orange</td>\n",
       "      <td>767135</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40452</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.175667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.032850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>538081</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30731</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.244632</td>\n",
       "      <td>0.639706</td>\n",
       "      <td>0.029358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Orange</td>\n",
       "      <td>878133</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17585</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.141184</td>\n",
       "      <td>0.610294</td>\n",
       "      <td>0.682753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>328921</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36227</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.097918</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.025092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>445278</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30602</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.093038</td>\n",
       "      <td>0.595588</td>\n",
       "      <td>0.026010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Orange</td>\n",
       "      <td>440330</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bedrooms      sqft  yearbuilt   lotsize  pools    fips_name  valuation  \\\n",
       "11614       0.4  0.072978   0.566176  0.030479    0.0       Orange     431697   \n",
       "24479       0.4  0.090544   0.514706  0.033159    0.0  Los Angeles      84959   \n",
       "35314       0.4  0.174040   0.242647  0.031074    0.0  Los Angeles     693683   \n",
       "1237        0.4  0.144546   0.882353  0.039603    0.0  Los Angeles     494867   \n",
       "35388       0.4  0.227825   0.838235  0.017195    0.0       Orange     767135   \n",
       "40452       0.4  0.175667   0.875000  0.032850    0.0  Los Angeles     538081   \n",
       "30731       0.6  0.244632   0.639706  0.029358    0.0       Orange     878133   \n",
       "17585       0.4  0.141184   0.610294  0.682753    0.0  Los Angeles     328921   \n",
       "36227       0.6  0.097918   0.514706  0.025092    0.0  Los Angeles     445278   \n",
       "30602       0.4  0.093038   0.595588  0.026010    0.0       Orange     440330   \n",
       "\n",
       "       fips_name_Los Angeles  fips_name_Orange  fips_name_Ventura  \n",
       "11614                      0                 1                  0  \n",
       "24479                      1                 0                  0  \n",
       "35314                      1                 0                  0  \n",
       "1237                       1                 0                  0  \n",
       "35388                      0                 1                  0  \n",
       "40452                      1                 0                  0  \n",
       "30731                      0                 1                  0  \n",
       "17585                      1                 0                  0  \n",
       "36227                      1                 0                  0  \n",
       "30602                      0                 1                  0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled, validate_scaled, test_scaled = scale_zillow(train, validate, test)\n",
    "train_scaled.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e684472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_scaled.drop(columns=['fips_name','valuation'])\n",
    "y_train = train_scaled.valuation\n",
    "\n",
    "X_validate = validate_scaled.drop(columns=['fips_name','valuation'])\n",
    "y_validate = validate_scaled.valuation\n",
    "\n",
    "X_test = test_scaled.drop(columns=['fips_name','valuation'])\n",
    "y_test = test_scaled.valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c3a6b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sqft']\n",
      "['bedrooms', 'sqft']\n",
      "['bedrooms', 'sqft', 'pools']\n",
      "['bedrooms', 'sqft', 'yearbuilt', 'pools']\n",
      "['bedrooms', 'sqft', 'yearbuilt', 'lotsize', 'pools']\n",
      "['bedrooms', 'sqft', 'yearbuilt', 'lotsize', 'pools', 'fips_name_Orange']\n",
      "['bedrooms', 'sqft', 'yearbuilt', 'lotsize', 'pools', 'fips_name_Los Angeles', 'fips_name_Orange']\n",
      "['bedrooms', 'sqft', 'yearbuilt', 'lotsize', 'pools', 'fips_name_Los Angeles', 'fips_name_Orange', 'fips_name_Ventura']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "for i in range(1,9):\n",
    "    # parameters: f_regression stats test, give me 8 features\n",
    "    f_selector = SelectKBest(f_regression, k=i)\n",
    "\n",
    "    # find the top 8 X's correlated with y\n",
    "    f_selector.fit(X_train, y_train)\n",
    "\n",
    "    # boolean mask of whether the column was selected or not. \n",
    "    feature_mask = f_selector.get_support()\n",
    "\n",
    "    # get list of top K features. \n",
    "    f_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "    print(f_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39c31b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sqft']\n",
      "['sqft', 'fips_name_Ventura']\n",
      "['sqft', 'fips_name_Orange', 'fips_name_Ventura']\n",
      "['sqft', 'fips_name_Los Angeles', 'fips_name_Orange', 'fips_name_Ventura']\n",
      "['bedrooms', 'sqft', 'fips_name_Los Angeles', 'fips_name_Orange', 'fips_name_Ventura']\n",
      "['bedrooms', 'sqft', 'lotsize', 'fips_name_Los Angeles', 'fips_name_Orange', 'fips_name_Ventura']\n",
      "['bedrooms', 'sqft', 'yearbuilt', 'lotsize', 'fips_name_Los Angeles', 'fips_name_Orange', 'fips_name_Ventura']\n",
      "['bedrooms', 'sqft', 'yearbuilt', 'lotsize', 'pools', 'fips_name_Los Angeles', 'fips_name_Orange', 'fips_name_Ventura']\n",
      "['bedrooms', 'sqft', 'yearbuilt', 'lotsize', 'pools', 'fips_name_Los Angeles', 'fips_name_Orange', 'fips_name_Ventura']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "for i in range(1,9):\n",
    "# initialize the ML algorithm\n",
    "    lm = LinearRegression()\n",
    "\n",
    "    # create the rfe object, indicating the ML object (lm) and the number of features I want to end up with. \n",
    "    rfe = RFE(lm, n_features_to_select=i)\n",
    "\n",
    "    # fit the data using RFE\n",
    "    rfe.fit(X_train,y_train)  \n",
    "\n",
    "    # get the mask of the columns selected\n",
    "    feature_mask = rfe.support_\n",
    "\n",
    "    # get list of the column names. \n",
    "    rfe_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "    print(rfe_feature)\n",
    "\n",
    "rfecv = RFECV(lm, min_features_to_select = 1)\n",
    "rfecv.fit(X_train, y_train)\n",
    "feature_mask = rfecv.support_\n",
    "rfecv_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "print(rfecv_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ace406c",
   "metadata": {},
   "source": [
    "##### I performed both a SelecKBest and RFE.  RFE ran without issue and is considered the superiros one, so went with it.\n",
    "##### Then used an RFE Cross Validation funtion to determine optial number of features, and it looks like we should model using all of the features ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d1de5c",
   "metadata": {},
   "source": [
    "# VI. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e36a8c2",
   "metadata": {},
   "source": [
    "#### BASELINE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daef897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30d3731f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using Mean\n",
      "Train/In-Sample:  495485.97678 \n",
      "Validate/Out-of-Sample:  465856.70737\n",
      "RMSE using Median\n",
      "Train/In-Sample:  510083.1964 \n",
      "Validate/Out-of-Sample:  479220.83355\n"
     ]
    }
   ],
   "source": [
    "# We need y_train and y_validate to be dataframes to append the new columns with predicted values. \n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_validate = pd.DataFrame(y_validate)\n",
    "\n",
    "# 1. Predict target_pred_mean\n",
    "valuation_pred_mean = y_train['valuation'].mean()\n",
    "y_train['valuation_pred_mean'] = valuation_pred_mean\n",
    "y_validate['valuation_pred_mean'] = valuation_pred_mean\n",
    "\n",
    "# 2. compute target_pred_median\n",
    "valuation_pred_median = y_train['valuation'].median()\n",
    "y_train['valuation_pred_median'] = valuation_pred_median\n",
    "y_validate['valuation_pred_median'] = valuation_pred_median\n",
    "\n",
    "# 3. RMSE of target_pred_mean\n",
    "rmse_train_mean = mean_squared_error(y_train.valuation, y_train.valuation_pred_mean)**(1/2)\n",
    "rmse_validate_mean = mean_squared_error(y_validate.valuation, y_validate.valuation_pred_mean)**(1/2)\n",
    "\n",
    "print(\"RMSE using Mean\\nTrain/In-Sample: \", round(rmse_train_mean, 5), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate_mean, 5))\n",
    "\n",
    "# 4. RMSE of G3_pred_median\n",
    "rmse_train_median = mean_squared_error(y_train.valuation, y_train.valuation_pred_median)**(1/2)\n",
    "rmse_validate_median = mean_squared_error(y_validate.valuation, y_validate.valuation_pred_median)**(1/2)\n",
    "\n",
    "print(\"RMSE using Median\\nTrain/In-Sample: \", round(rmse_train_median, 5), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate_median, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d358d4",
   "metadata": {},
   "source": [
    "#### OLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cff7fa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for OLS using LinearRegression\n",
      "Training/In-Sample:  384906.39842239546 \n",
      "Validation/Out-of-Sample:  369566.43744094815\n"
     ]
    }
   ],
   "source": [
    "# create the model object\n",
    "lm = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm.fit(X_train, y_train.valuation)\n",
    "\n",
    "# predict train\n",
    "y_train['valuation_pred_lm'] = lm.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.valuation, y_train.valuation_pred_lm)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['valuation_pred_lm'] = lm.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.valuation, y_validate.valuation_pred_lm)**(1/2)\n",
    "\n",
    "print(\"RMSE for OLS using LinearRegression\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5affd7f9",
   "metadata": {},
   "source": [
    "#### LASSOLARS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84a0e22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Lasso + Lars\n",
      "Training/In-Sample:  384900.1347973966 \n",
      "Validation/Out-of-Sample:  369482.21796410286\n"
     ]
    }
   ],
   "source": [
    "# create the model object\n",
    "lars = LassoLars(alpha=2.0)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lars.fit(X_train, y_train.valuation)\n",
    "\n",
    "# predict train\n",
    "y_train['valuation_pred_lars'] = lars.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.valuation, y_train.valuation_pred_lars)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['valuation_pred_lars'] = lars.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.valuation, y_validate.valuation_pred_lars)**(1/2)\n",
    "\n",
    "print(\"RMSE for Lasso + Lars\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ba7db",
   "metadata": {},
   "source": [
    "#### TWEEDIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca502bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for GLM using Tweedie, power=1 & alpha=0\n",
      "Training/In-Sample:  416065.37577210896 \n",
      "Validation/Out-of-Sample:  392293.512460416\n"
     ]
    }
   ],
   "source": [
    "# create the model object\n",
    "glm = TweedieRegressor(power=1, alpha=0)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "glm.fit(X_train, y_train.valuation)\n",
    "\n",
    "# predict train\n",
    "y_train['valuation_pred_glm'] = glm.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.valuation, y_train.valuation_pred_glm)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['valuation_pred_glm'] = glm.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.valuation, y_validate.valuation_pred_glm)**(1/2)\n",
    "\n",
    "print(\"RMSE for GLM using Tweedie, power=1 & alpha=0\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3082d0c",
   "metadata": {},
   "source": [
    "#### POLYNOMIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0620b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree=3)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree2 = pf.fit_transform(X_train)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree2 = pf.transform(X_validate)\n",
    "X_test_degree2 = pf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bf8820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Polynomial Model, degrees=2\n",
      "Training/In-Sample:  370900.6881775274 \n",
      "Validation/Out-of-Sample:  360923.02494560473\n"
     ]
    }
   ],
   "source": [
    "# create the model object\n",
    "lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm2.fit(X_train_degree2, y_train.valuation)\n",
    "\n",
    "# predict train\n",
    "y_train['valuation_pred_lm2'] = lm2.predict(X_train_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.valuation, y_train.valuation_pred_lm2)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['valuation_pred_lm2'] = lm2.predict(X_validate_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.valuation, y_validate.valuation_pred_lm2)**(1/2)\n",
    "\n",
    "print(\"RMSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fed8cb",
   "metadata": {},
   "source": [
    "#### Polynomial Regression of 3 is the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f79465",
   "metadata": {},
   "source": [
    "# VII. TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "820eee77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for OLS Model using LinearRegression\n",
      "Out-of-Sample Performance:  379421.06253291364\n"
     ]
    }
   ],
   "source": [
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "# predict on test\n",
    "y_test['valuation_pred_lm'] = lm2.predict(X_test_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_test = mean_squared_error(y_test.valuation, y_test.valuation_pred_lm)**(1/2)\n",
    "\n",
    "print(\"RMSE for OLS Model using LinearRegression\\nOut-of-Sample Performance: \", rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934e66db",
   "metadata": {},
   "source": [
    "### Sidequest - Adding in quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e90df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea638bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual.drop(columns='fips_name')\n",
    "validate_qual.drop(columns='fips_name')\n",
    "test_qual.drop(columns='fips_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual = train_qual.astype({'bedrooms':'int', 'sqft':'int', 'valuation':'int', 'yearbuilt':'int','lotsize':'int','pools':'int','quality':'int'})\n",
    "validate_qual = validate_qual.astype({'bedrooms':'int', 'sqft':'int', 'valuation':'int', 'yearbuilt':'int','lotsize':'int','pools':'int','quality':'int'})\n",
    "test_qual = test_qual.astype({'bedrooms':'int', 'sqft':'int', 'valuation':'int', 'yearbuilt':'int','lotsize':'int','pools':'int','quality':'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26bb021",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_scale, validate_qual_scale, test_qual_scale = scale_zillow(train_qual, validate_qual, test_qual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9621c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_qual_scale.drop(columns=['valuation'])\n",
    "y_train = train_qual_scale.valuation\n",
    "\n",
    "X_validate = validate_qual_scale.drop(columns=['valuation'])\n",
    "y_validate = validate_qual_scale.valuation\n",
    "\n",
    "X_test = test_qual_scale.drop(columns=['valuation'])\n",
    "y_test = test_qual_scale.valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfe4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bd414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['fips_name','fips_name_Los Angeles'])\n",
    "X_validate = X_validate.drop(columns=['fips_name','fips_name_Los Angeles'])\n",
    "X_test = X_test.drop(columns=['fips_name','fips_name_Los Angeles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,7):\n",
    "# initialize the ML algorithm\n",
    "    lm = LinearRegression()\n",
    "\n",
    "    # create the rfe object, indicating the ML object (lm) and the number of features I want to end up with. \n",
    "    rfe = RFE(lm, n_features_to_select=i)\n",
    "\n",
    "    # fit the data using RFE\n",
    "    rfe.fit(X_train,y_train)  \n",
    "\n",
    "    # get the mask of the columns selected\n",
    "    feature_mask = rfe.support_\n",
    "\n",
    "    # get list of the column names. \n",
    "    rfe_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "    print(rfe_feature)\n",
    "\n",
    "rfecv = RFECV(lm, min_features_to_select = )\n",
    "rfecv.fit(X_train, y_train)\n",
    "feature_mask = rfecv.support_\n",
    "rfecv_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "print(rfecv_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f6a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need y_train and y_validate to be dataframes to append the new columns with predicted values. \n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_validate = pd.DataFrame(y_validate)\n",
    "\n",
    "# 1. Predict target_pred_mean\n",
    "valuation_pred_mean = y_train['valuation'].mean()\n",
    "y_train['valuation_pred_mean'] = valuation_pred_mean\n",
    "y_validate['valuation_pred_mean'] = valuation_pred_mean\n",
    "\n",
    "# 2. compute target_pred_median\n",
    "valuation_pred_median = y_train['valuation'].median()\n",
    "y_train['valuation_pred_median'] = valuation_pred_median\n",
    "y_validate['valuation_pred_median'] = valuation_pred_median\n",
    "\n",
    "# 3. RMSE of target_pred_mean\n",
    "rmse_train_mean = mean_squared_error(y_train.valuation, y_train.valuation_pred_mean)**(1/2)\n",
    "rmse_validate_mean = mean_squared_error(y_validate.valuation, y_validate.valuation_pred_mean)**(1/2)\n",
    "\n",
    "print(\"RMSE using Mean\\nTrain/In-Sample: \", round(rmse_train_mean, 5), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate_mean, 5))\n",
    "\n",
    "# 4. RMSE of G3_pred_median\n",
    "rmse_train_median = mean_squared_error(y_train.valuation, y_train.valuation_pred_median)**(1/2)\n",
    "rmse_validate_median = mean_squared_error(y_validate.valuation, y_validate.valuation_pred_median)**(1/2)\n",
    "\n",
    "print(\"RMSE using Median\\nTrain/In-Sample: \", round(rmse_train_median, 5), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate_median, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d76135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lm = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm.fit(X_train, y_train.valuation)\n",
    "\n",
    "# predict train\n",
    "y_train['valuation_pred_lm'] = lm.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.valuation, y_train.valuation_pred_lm)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['valuation_pred_lm'] = lm.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.valuation, y_validate.valuation_pred_lm)**(1/2)\n",
    "\n",
    "print(\"RMSE for OLS using LinearRegression\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9342d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lars = LassoLars(alpha=2.0)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lars.fit(X_train, y_train.valuation)\n",
    "\n",
    "# predict train\n",
    "y_train['valuation_pred_lars'] = lars.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.valuation, y_train.valuation_pred_lars)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['valuation_pred_lars'] = lars.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.valuation, y_validate.valuation_pred_lars)**(1/2)\n",
    "\n",
    "print(\"RMSE for Lasso + Lars\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "glm = TweedieRegressor(power=1, alpha=0)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "glm.fit(X_train, y_train.valuation)\n",
    "\n",
    "# predict train\n",
    "y_train['valuation_pred_glm'] = glm.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.valuation, y_train.valuation_pred_glm)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['valuation_pred_glm'] = glm.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.valuation, y_validate.valuation_pred_glm)**(1/2)\n",
    "\n",
    "print(\"RMSE for GLM using Tweedie, power=1 & alpha=0\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f5bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree2 = pf.fit_transform(X_train)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree2 = pf.transform(X_validate)\n",
    "X_test_degree2 = pf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm2.fit(X_train_degree2, y_train.valuation)\n",
    "\n",
    "# predict train\n",
    "y_train['valuation_pred_lm2'] = lm2.predict(X_train_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.valuation, y_train.valuation_pred_lm2)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['valuation_pred_lm2'] = lm2.predict(X_validate_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.valuation, y_validate.valuation_pred_lm2)**(1/2)\n",
    "\n",
    "print(\"RMSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
